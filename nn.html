<body style="font-family: monaco">

    <strong>ICLR 2019</strong>
    <ol>
    <li>ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware</li>
    <li>Defensive Quantization: When Efficiency Meets Robustness</li>
    </ol>
    <hr>
    <strong>CVPR 2019</strong>
    <ol>
    <li>HAQ: Hardware-Aware Automated Quantization with Mixed Precision</li>
    </ol>
    <hr>
    <strong>NeurIPS 2019</strong>
    <ol>
    <li>Deep Leakage from Gradients</li>
    <li>Post Training 4-bit Quantization of Convolutional Networks for Rapid Deployment</li>
    <li>Dimension Free Bounds for Low-Precision Training</li>
    <li>AutoAssist: A Framework to Accelerate Training of Deep Neural Networks</li>
    <li>Backprop with Approximate Activations for Memory-efficient Network Training</li>
    <li>E<sup>2</sup>-Train: Training State-of-the-art CNNs with Over 80% Energy Savings</li>
    <li>Hybrid 8-bit Floating Point (H8FP) for Training and Inference for Deep Neural Networks</li>
    
</body>
